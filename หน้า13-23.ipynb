{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ทฤษฎี: คุณสมบัติไม่แปรเปลี่ยน (invariance property) ของตัวประมาณ ค่าด้วยความเป็นไปได้สูงสุด (MLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ตัวประมาณค่าด้วยความเป็นไปได้สูงสุด (MLE) มีคุณสมบัติอย่างหนึ่งที่สำคัญที่ช่วยให้ สามารถประยุกต์ใช้ได้อย่างกว้างขวาง โดยเรามักเรียกคุณสมบัตินี้ว่า คุณสมบัติไม่แปร เปลี่ยน (invariance property) ซึ่งมีความหมายดังแสดงในทฤษฎีบทต่อไปนี้\n",
    "\n",
    "#### Theorem\n",
    "\n",
    "ถ้า $\\hat{\\theta}_{MLE}$ คือตัวประมาณค่าด้วยความเป็นไปได้สูงสุด (MLE) ของ $\\theta$ และ g เป็นฟังก์ชันที่กำหนด โดย  $\\gamma = g(\\theta)$ แล้ว $g(\\hat{\\theta}_{MLE})$ เป็นตัวประมาณค่าด้วยความเป็นไปได้สูงสุด (MLE) ของ $\\gamma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### การพิสูจน์: คุณสมบัติไม่แปรเปลี่ยน (invariance property) ของตัว ประมาณค่าด้วยความเป็นไปได้สูงสุด (MLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proof\n",
    "\n",
    "- เพื่อความสะดวก ขอนำเสนอ การพิสูจน์ในกรณีที่ g เป็นฟังก์ชันหนึ่งต่อหนึ่ง (one-on-one) เท่านั้น โดยเริ่มจาก การที่ $\\hat{\\theta}_{MLE}$ เป็นตัวประมาณค่าด้วยความเป็นไป ได้สูงสุด (MLE) ของ $\\theta$ หมายความว่า\n",
    "$$ \\hat{\\theta}_{MLE} = argmax_\\theta \\prod_{i=1}^{n}f_i(x_i|\\theta) ---------(10) $$\n",
    "\n",
    "- การที่ g เป็นฟังก์ชันหนึ่งต่อหนึ่ง (one-on-one) หมายความว่า เราสามารถใช้ฟังก์ชันส่วนกลับได้เป็น $\\theta = g^{−1} (\\gamma)$ ดังนั้น เราสามารถเขียนฟังก์ชันความเป็นไป ได้ (likelihood function) ในรูปฟังก์ชันของ $L$ ได้เป็น\n",
    "\n",
    "$$ L(\\gamma|x) = argmax_\\gamma \\prod_{i=1}^{n}f_i(x_i|g^{-1}(\\gamma)) ---------(11) $$\n",
    "\n",
    "- ดังนั้น เนื่องจากฟังก์ชันความเป็นไปได้ (likelihood function) ในสมการที่ 10 มีค่าสูงสุดเมื่อพารามิเตอร์$\\theta$ มีค่าเท่ากับ $\\hat{\\theta}_{MLE}$ ดังนั้น ฟังก์ชันความเป็นไปได้ (likelihood function) ในสมการที่ 11 จะมีค่าสูงสุด ถ้าพารามิเตอร์$\\gamma$ มีค่าเท่ากับ $\\hat{\\gamma}_{MLE}$ ที่ทำให้ $\\hat{\\theta}_{MLE} = g^{-1}(\\hat{\\gamma}_{MLE})$ นั่นคือ $ \\hat{\\gamma}_{MLE} = g(\\hat{\\theta}_{MLE}) $\n",
    "\n",
    "- ส่วนในกรณีที่ฟังก์ชัน g ไม่ใช่ฟังก์ชันหนึ่งต่อหนึ่ง ก็สามารถพิสูจน์ได้ด้วยวิธีการที่คล้ายคลึงกัน แต่ต้องตระหนักว่าสิ่งที่ต้องการคือค่าที่ต้องการนำไปสู่ค่าสูงสุด ถึงแม้ว่า อาจจะมีค่าพารามิเตอร์ที่ทำให้ได้ค่าสูงสุดหลายค่า"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ตัวอย่าง: คุณสมบัติไม่แปรเปลี่ยน (invariance property) ของตัว ประมาณค่าด้วยความเป็นไปได้สูงสุด (MLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "สมมุติให้$X_1, . . . , X_n$ เป็นกลุ่มตัวอย่างสุ่มที่เลือกมาการแจกแจงแบบเอกรูป (uniform distribution) ในช่วง $[0,c]$ เช่นเดียวกับตัวอย่างที่แล้วซึ่งพิสูจน์แล้วว่า ตัวประมาณค่า ด้วย ความเป็นไปได้สูงสุด (MLE) ของ c มีค่าเท่ากับ$ \\hat{c}_{MLE} = max(X_1, . . . , X_n)$ เราสามารถประยุกต์ใช้คุณสมบัติไม่แปรเปลี่ยน (invariance property) เพื่อหา ตัวประมาณค่า ของความแปรปรวน (variance) ของ X ได้โดยเริ่มจากการที่ทราบว่า$Var [X] = \\frac {c^2}{12}$ ในขณะ เดียวกันเราก็ทราบว่า ตัวประมาณค่า $\\hat{c}_{MLE}= max(X_1, . . . , X_n)$ ดังนั้น\n",
    "\n",
    "$$\\hat{Var}[X] = \\frac{\\hat{C}^2_{MLE}}{12} = \\frac{max(x_1,\\dots,x_n)^2}{12}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ความคงเส้นคงวา (consistency) ของตัวประมาณค่าด้วยความเป็นไปได้ สูงสุด (MLE)\n",
    "\n",
    "- คุณสมบัติอันหนึ่งที่สำคัญของ ตัวประมาณค่า ด้วยความเป็นไปได้สูงสุด (MLE) คือ ความ คงเส้นคงวา (consistency) นั่นคือ เมื่อ กลุ่มตัวอย่างมีขนาดใหญ่มากพอ แล้ว ตัว ประมาณค่าด้วยความเป็นไปได้สูงสุด (MLE) จะมีค่าใกล้เคียงกับค่าที่แท้จริง\n",
    "\n",
    "- ทฤษฎีบทและการพิสูจน์ด้านล่างนี้ดัดแปลงมาจาก Hogg et al.(2005) โดยเริ่มจากการ กำหนดเงื่อนไขปกติ (regularity conditions) ต่อไปนี้ \n",
    "\n",
    "  RC1 ฟังก์ชันความหนาแน่นของความน่าจะเป็น (p.d.f.) $f(x, \\theta)$ แตกต่างกันชัดเจน หมายความ ว่า ถ้า$ \\theta\\ne\\theta′$ แล้ว $f(x,\\theta)\\ne f(x,\\theta′)$\n",
    "  \n",
    "  RC2 ฟังก์ชันความหนาแน่นของความน่าจะเป็น (p.d.f.) $f(x,\\theta)$ มีส่วนค้ำจุน (support) S เหมือนกันสำหรับทุกๆ ค่าพารามิเตอร์$\\theta$\n",
    "  \n",
    "  RC3 ค่าที่แท้จริง $\\theta_0$ ของพารามิเตอร์$\\theta$ เป็น จุดภายใน (interior point) ของเซ็ต$\\Theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ทฤษฎี: ความคงเส้นคงวา (consistency) ของตัวประมาณค่าด้วยความ เป็นไปได้สูงสุด (MLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theorem\n",
    "สมมุติว่าตัวแปรสุ่ม $X_1,\\dots, X_n$ สอดคล้องกับเงื่อนไขปกติ (regularity conditions) RC1 - RC3 โดยที่ $\\theta_0$ เป็นค่าพารามิเตอร์ที่แท้จริง (true parameter) และ $f(x|\\theta)$ สามารถหาค่าอนุพันธ์ เทียบกับ $\\theta$ ได้ แล้ว คำตอบของสมการความเป็นไปได้ (likelihood equation) $\\hat{\\theta}$ ซึ่งสอดคล้อง กับสมการต่อไปนี้\n",
    "$$ \\frac{ \\partial\\log L(\\hat{\\theta}|X)}{ \\partial\\theta}  = 0 ---------(12) $$\n",
    "\n",
    "จะมีความคงเส้นคงวา (consistent) นั่นคือ $ \\hat{\\theta}  \\rightarrow^p \\theta_0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ตัวอย่าง: ความคงเส้นคงวา (consistency) ของตัวประมาณค่าด้วยความ เป็นไปได้สูงสุด (MLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "พิจารณาตัวอย่าง $X_1,\\dots, X_n$ โดยที่ $X_i$ มีการแจกแจงแบบเบอร์นูลลี (Bernoulli distribution) สำหรับพารามิเตอร์ $\\theta$ ดังนั้นตัว ประมาณค่าด้วยความเป็นไปได้สูงสุด (MLE)\n",
    "\n",
    "$$ \\hat{\\theta}_{MLE}(X) = \\frac {\\sum_{i=1}^{n}X_i}{n} = \\bar X_n ---------(13) $$\n",
    "\n",
    "- เราสุ่มตัวอย่างจาก การแจกแจงแบบเบอร์นูลลี (Bernoulli distribution) โดยกำหนดพารามิเตอร์$\\theta$ = 0.4 แล้ว นำข้อมูล จากการสุ่มนั้นมาประมาณพบว่า\n",
    "<img src=\"images/1.5.jpg\" width=400 align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### บทนำ: การประมาณค่าด้วยโมเมนต์ (Method of Moments)\n",
    "\n",
    "- การประมาณค่าด้วยโมเมนต์ (method of moments หรือเรียกสั้นๆ ว่า MM) เป็นวิธี ประมาณค่าอย่างง่ายที่อาศัยหลักการพื้นฐานที่ว่า ค่าคาดหมายจากตัวอย่าง (sample mean) $\\bar X_n$ คือตัวประมาณค่า (estimator) ที่ดีสำหรับค่าคาดหมาย (population mean) $E[X]$ ซึ่งเป็นหลักการที่ประยุกต์ใช้อย่างกว้างขวาง แม้แต่ในกรณีของการประมาณ ค่าที่ซับซ้อน\n",
    "\n",
    "- ข้อดีอีกอย่างหนึ่งของการประมาณค่าด้วยโมเมนต์ (MM) ก็คือการที่สามารถหาตัวประมาณ ค่า (estimator) ได้ค่อนข้างแน่นอน ซึ่งต่างจากวิธีการประมาณค่าด้วยความเป็นไปได้สูงสุด (Maximum Likelihood Estimation หรือเรียกสั้นๆ ว่า MLE) ที่อาจจะไม่สามารถหาตัว ประมาณค่าได้ (estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### การประมาณค่าด้วยโมเมนต์ (Method of Moments)\n",
    "\n",
    "- กำหนดให้$X_1,\\dots, X_n$ เป็น ตัวอย่างที่สุ่มมาจากประชากร ที่มีฟังก์ชันความหนาแน่นของ ความน่าจะเป็น (p.d.f.) หรือฟังก์ชันความน่าจะเป็น (p.f.)$ f(x|\\theta_1,\\dots, \\theta_k)$\n",
    "\n",
    "- วิธีการประมาณค่าด้วยโมเมนต์ (MM) ของพารามิเตอร์$\\theta = (\\theta_1,\\dots, \\theta_k)$ เริ่มได้ด้วยการ กำหนดให้k โมเมนต์จากตัวอย่าง (sample moments) มีค่าเท่ากับ k โมเมนต์จาก ประชากร (population moments) ซึ่งเป็นฟังก์ชันของพารามิเตอร์$\\theta$\n",
    "\n",
    "- ผลลัพธ์จากขั้นตอนนี้คือ ระบบสมการของ k สมการที่มีตัวไม่ทราบค่า (unknown) ทั้งหมด k ตัว ขั้นตอนสุดท้ายคือการแก้ระบบสมการนี้ โดยที่ผลลัพธ์ที่ได้จะอยู่ในรูปของฟังก์ชัน $\\theta_i (X_1,\\dots, X_n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### โมเมนต์จากตัวอย่าง (sample moments)\n",
    "\n",
    "- กำหนดให้$M_j = \\frac{1}{n}\\sum_{i=1}^{n}X^j_i$ แทน โมเมนต์จากตัวอย่าง (sample moments) อันดับที่ $j = 1, . . . ,k$ และ $\\mu_j (\\theta_1,\\dots,\\theta_k) = E[X^j ]$ แทน โมเมนต์จากประชากร (population moments) อันดับที่ j = 1, . . . ,k\n",
    "\n",
    "- การประมาณค่าด้วยโมเมนต์ (MM) คือการแก้ระบบสมการต่อไปนี้ \n",
    "$$ \\frac{1}{n} \\sum_{i=1}^{n} X_i = \\mu_1(\\theta_1,\\dots,\\theta_k) ---------(14) $$\n",
    "$$ \\frac{1}{n} \\sum_{i=1}^{n} X_i^2 = \\mu_2(\\theta_1,\\dots,\\theta_k) ---------(15) $$\n",
    " $$\\vdots $$\n",
    "$$ \\frac{1}{n} \\sum_{i=1}^{n} X_i^k = \\mu_k(\\theta_1,\\dots,\\theta_k) ---------(17) $$\n",
    "\n",
    "- นี่คือระบบสมการที่มีทั้งหมด k สมการและมีตัวไม่ทราบค่าทั้งหมด k ตัว "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ตัวอย่าง: การประมาณค่าด้วยโมเมนต์ (Method of Moments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "สมมุติว่า เป็นตัวอย่างสุ่มที่มีมีการแจกแจงเหมือนกันและเป็นอิสระต่อกัน (i.i.d.) แบบปกติN $(\\mu, \\sigma^2 )$ นั่นคือ พารามิเตอร์ที่ต้องการทราบค่าในตัวอย่างนี้มีทั้งหมด 2 ตัวคือ $\\theta_1 = \\mu \\theta_2 = \\sigma^2$\n",
    "\n",
    "- เราจำเป็นต้องใช้โมเมนต์ที่หนึ่งและโมเมนต์ที่สอง\n",
    "$$ \\frac{1}{n}\\sum_{i=1}^{n}X_i = \\mu , \\frac{1}{n}\\sum_{i=1}^{n}X_i^2  = E[X^2] = \\sigma^2 + \\mu^2$$\n",
    "\n",
    "- ตัวประมาณค่าด้วยโมเมนต์ (MM estimators) ในกรณีนี้เท่ากับ\n",
    "$$ µ = \\frac{1}{n}\\sum_{i=1}^{n}X_i  \\equiv \\bar X , \\sigma^2 = \\frac{1}{n}\\sum_{i=1}^{n}(X_i - \\bar X)^2 $$\n",
    "\n",
    "- ตัวประมาณค่าสำหรับค่าคาดหมายและค่าความแปรปรวนที่ใช้กันอยู่ทั่วไป อาจจะแตกต่างบ้างเล็กน้อยในกรณี ของค่าความแปรปรวนที่หารด้วย n ไม่ใช่n – 1\n",
    "\n",
    "- ความแตกต่างตรงนี้มีผลต่อความเบี่ยงเบน (bias) ของตัวประมาณค่าในทางทฤษฎี แต่ในทางปฏิบัติหาก n มีค่า มากพอแล้ว ค่าประมาณที่ได้จะมีค่าใกล้เคียงกันมาก"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### การประมาณค่าด้วยโมเมนต์ (Method of Moments)\n",
    "\n",
    "- อย่างไรก็ตาม วิธีการประมาณค่าด้วยโมเมนต์ (MM) ก็มีจุดอ่อน ทั้งนี้ส่วนหนึ่งเป็นเพราะ โมเมนต์เพียงไม่กี่อันอาจจะไม่สามารถบอกคุณสมบัติของการแจกแจงได้ดีพอ เพราะหาก ต้องการให้ครอบคลุมทั้งหมดต้องใช้โมเมนต์ทุกอัน \n",
    "- ทฤษฎีบทต่อไปนี้สรุปว่า ตัวประมาณค่าด้วยโมเมนต์ (MM) มีความคงเส้นคงวา (consistent) นั่นคือ เมื่อจำนวนตัวอย่างมากพอแล้ว ค่าประมาณด้วยโมเมนต์ (MM) จะมี ค่าใกล้เคียงกับค่าพารามิเตอร์ที่แท้จริง (true parameter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
